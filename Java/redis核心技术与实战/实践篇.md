# 实践篇
[toc]


## 11 万金油的String，为什么不好用了？


开发一个图片存储系统，要求这个系统能快速地记录图片ID和图片在存储系统中保存时的ID（可以直接叫做图片存储对象ID）。还要能够根据图片ID快速查找到图片存储对象ID。

因为图片数量巨大，所以就用10位数来表示图片ID和图片存储对象ID，例如，图片ID为1101000051，它在存储系统中对应的ID号是3301000051 .


可以看到，图片ID和图片存储对象ID正好一一对应，是典型的“键-单值”模式。所谓的“单值”，就是指键值对中的值就是一个值，而不是一个集合，这和String类型提供的“一个键对应一个值的数据”的保存形式正好契合。


第一个方案就是用 String 保存数据。我们把图片 ID 和图片存储对象 ID 分别作为键值对的 key 和 value 来保存，其中，图片存储对象 ID 用了**String 类型**。



但是随着图片数据量的不断增加，redis内存使用量也在增加，结果就遇到了大内存Redis实例因为生成RDB而响应变慢的问题。


**String 类型并不是是用于所有场合的，它有一个明显的短板，就是它保存数据时所消耗的内存空间较多。**


### 为什么String 类型内存开销大

在上面的案例中，一亿张图片的信息，用了约6.4GB的内存，一个图片的ID和图片存储对象ID的记录平均用了64字节。 但实际上，只需要16字节就可以了。

图片ID和图片存储对象ID都是 10位数，我们可以用两个8字节的Long类型标识这两个ID。因为8字节的Long类型最大可以表示2的64次方的数值，所以肯定可以表示10位数。 但是String 类型却用了64字节。

因为除了记录实际数据，String 类型 还需要额外的**内存空间**记录**数据长度**，**空间使用**等信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较大了。

![](images/2021-07-03-21-09-36.png)


然而，由于Redis 的数据类型很多，不同的数据类型都有相同的元数据要记录（最后访问时间，被引用的次数等等），因此，Redis 会用一个RedisObject结构体来统一记录这些元数据，同时指向实际数据。


![](images/2021-07-03-21-12-47.png)
为了节省内存空间，Redis 还对Long 类型整数和 SDS的内存布局做了专门的设计。

当保存的是Long类型整数时，RedisObject的指针就直接复制位整数数据。、

当保存字符串数据，如果字符串长度小于等于44字节，RedisObject中的元数据，指针和SDS是一块连续的内存区域，这样就可以避免内存碎片。 （embstr编码方式）

如果大于44字节，会给sds分配独立的空间，用指针指向SDS结构。（raw编码模式）

![](images/2021-07-03-21-13-33.png)


根据上面的RedisObject 所包含的额外元数据开销，就可以计算String 类型的内存使用量。

（8+8）*2=32 字节，两个ID加起来共使用32字节。还剩下32字节。

Redis 使用**全局哈希表**来保存所有键值对，哈希表的每一项是一个dictEntry 的结构体，用来指向一个键值对。 dictEntry结构中有三个8字节的指针，分别指向key，value以及下一个dictEntry，三个指针共24字节，如下图所示：

![](images/2021-07-03-21-29-27.png)

这里仅仅只有24字节，为什么占用了32字节？
（因为Redis 使用的内存分配库jemalloc）

jemalloc 会根据分配的内存，根据字节数N，找到一个比N大的最小的2次幂作为分配空间。
因此分配了32字节。


### 用什么数据结构可以节省内存？

Redis 有一个底层数据结构，叫压缩列表（ziplist），比较节省内存。


![](images/2021-07-03-21-33-16.png)
表头三个字段 zlbytes,zltail,zllen ：表示列表长度，列表尾的偏移量，以及列表中的entry个数。压缩列表还有一个zlend，表示列表结束。

压缩列表之所以可以节省内存，就在于它是用一系列连续的entry 保存数据。每个entry的元数据包含下面几部分。

* **prev_len**,表示前一个entry的长度。prev_len有两种取值情况：1字节或5字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1 字节的值能表示的数值范围是 0 到 255，但是压缩列表中zlend 的取值默认是 255，因此，就默认用 255 表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时，prev_len 取值为 1 字节，否则，就取值为 5 字节。
* len:表示自身长度，4字节
* encoding:表示编码方式，1字节
* content:保存实际数据。


接下来以之前的图片存储对象ID为例，来分析压缩列表是如何节省内存空间的。

每个entry保存一个图片存储对象ID（8字节），此时，每个entry 的prev_len 只需要1个字节就行，因为每个entry的前一个entry长度都只有8字节，小于254字节。这样一来，一个图片的存储对象ID所占用的内存大小是14字节(1+4+1+8),实际分配16字节。

Redis 基于压缩列表实现了 List、Hash 和 Sorted Set 这样的集合类型，这样做的最大好处就是节省了 **dictEntry的开销。**当你用 String 类型时，**一个键值对就有一个 dictEntry**，要用 32 字节空间。但采用集合类型时，**一个key 就对应一个集合的数据**，能保存的数据多了很多，但也只用了一个 dictEntry，这样就节省了内存。
这个方案听起来很好，但还存在一个问题：在用集合类型保存键值对时，一个键对应了一个集合的数据，但是在我们的场景中，**一个图片 ID 只对应一个图片的存储对象 ID，我们该怎么用集合类型呢？** 换句话说，在一个键对应一个值（也就是单值键值对）的情况下，我们该怎么用集合类型来保存这种单值键值对呢？



### 如何用集合类型保存单值的键值对
保存单值的键值对，可以采用基于Hash类型的二级编码方法。

就是把一个单值的数据拆分称为两部分，前一部分作为Hash 集合的key ，后一部分作为Hash集合的value。


Hash 类型底层结构什么使用压缩列表，什么时候使用哈希表呢？其实，hash类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash类型就会用哈希表来保存数据了。


![](images/2021-07-03-22-11-19.png)


## 12 有一亿个keys要统计，应该用哪种集合？
在web 和移动应用的业务场景中，我们经常需要保存这样一种信息：一个key对应了一个数据集合。举几个例子。
* 手机app中的每天的用户登录信息：一天对应一系列用户ID或移动设备ID
* 电商网站上商品的用户评论列表：一个商品对应了一系列的评论；
* 用户在手机App上的签到打卡信息：一天对应一系列用户的签到记录；
* 应用网站上的网页访问信息：一个网页对应一系列的访问点击。

redis 集合类型就是一个键对应一系列的数据，所以非常适合用来存取这些数据。但是，在这些场景中，除了记录信息，还需要对集合中的数据进行统计，例如：
* 在移动应用中，需要统计每天的新增用户数和第二天的留存用户数；
* 在电商网站的商品评论中，需要统计评论列表中的最新评论；
* 在签到打卡中，需要统计一个月内连续打卡的用户数；
* 在网页访问记录中，需要统计独立访客（Unique Visitor，UV）量。

因此需要选择出能够非常高效地统计大量数据（例如亿级）的集合类型。



### 聚合统计
集合元素统计的第一个场景： 聚合统计(**统计多个集合元素的聚合结果**)，包括：统计多个集合的共有元素（交集统计），把两个集合相比，统计其中一个集合独有的元素（差集统计);统计多个集合的所有元素（并集统计）。


统计手机App每天的新增用户数和第二天的留存用户数，正好对应了聚合统计。

要完成这个统计任务，我们可以用一个集合记录所有登录过App的用户ID，同时，用另一个集合记录每一天登录过App的用户ID。然后，在对这两个集合做聚合统计。


记录所有登录过app的用户id还是比较简单的，可以直接使用set类型，把key设置为user:id，表示记录的是用户ID，value就是一个set集合，里面是所有登录过App的用户ID，可以把这个set叫做累计用户set，如下图所示：

![](images/2021-07-05-16-46-41.png)

这个集合没有日期信息，不能直接统计每天的新增用户。所以，还需要把每一天登录的用户id，记录到一个新集合中，这个集合叫做每日用户set，有以下特点：
* key是user：id以及当天日期，例如 user:id:20200803
* value是set集合，记录当天登录的用户id
![](images/2021-07-05-16-51-37.png)


在统计每天的新增用户时，只要计算两个集合的差集即可。


命令

差集
```C
SDIFF key [key...]，从第一个key的集合中去除其他集合和自己的交集部分
SDIFFSTORE destination key [key...]，将差集结果存储在目标key中
```
交集
```c
SINTER key [key...]，取所有集合交集部分
SINTERSTORE destination key [key...]，将交集结果存储在目标key中
```

并集
```c
SUNION key [key...]，取所有集合的并集
SUNIONSTORE destination key [key...]，将并集结果存储在目标key中
```

####tips
set的差集，并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，容易导致实例阻塞。 可从**主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。**

### 排序统计

以上述的最新评论列表的场景为例，
最新评论列表包含了所有评论中的最新留言，这就要求 **集合类型能对元素排序**，也就是说，集合中的元素可以按序排列，这种对元素排序的集合类型叫做有序集合。


在Redis 常用的四个集合类型中（list,hash,set,sorted set）,list 和sorted set就属于有序集合。

（sorted set 就是zset ，因为Set的开头字母也是S，Sorted Set缩写为SSet不合适 ，会导致命令冲突 ，所以干脆用Z代替，ZSet出生了~它的出现也是解决set天生无序的问题）

list是按照元素进入list的顺序进行排序的，而sorted set 可以根据**元素的权重**来排序。可以自己来决定每个元素的权重值，先插入的元素权重小，后插入的元素权重大。

list是通过元素在list中的位置来排序的，当有一个新元素插入时，原先的元素会在list中的位置都后移了以为，原来排在第一位的元素现在排在了第二位。list相同位置上的元素就会发生变化。

和 List 相比，Sorted Set 就不存在这个问题，因为它是根据元素的实际权重来排序和获取数据的。我们可以按评论时间的先后给每条评论设置一个权重值，然后再把评论保存到 Sorted Set 中。Sorted Set 的ZRANGEBYSCORE 命令就可以按权重排序后返回元素。这样的话，即使集合中的元素频繁更新，Sorted Set 也能通过 ZRANGEBYSCORE 命令准确地获取到按序排列的数据。假设越新的评论权重越大，目前最新评论的权重是 N，我们执行下面的命令时，就可以获得最新的 10 条评论：
```c
ZRANGEBYSCORE comments N-9 N
```
#### tips
在面对需要展示最新列表，排行榜等场景时，如果数据更新频繁或者需要分页显示，建议使用zset。



### 二值状态统计
二值状态是指集合元素的取值就只有0或1两种。在签到打卡的场景中，我们只用记录签到（1）
或未签到（0），所以它就是非常典型的二值状态。

在签到统计时，每个用户一天的签到用一个bit位就能表示一个bit位就能表示，一个月的签到情况用31bit位就可以，而一年的签到也只需要用365个bit位，根本不用太复杂的集合类型。这个时候，就可以使用bitmap。 这是redis提供的扩展数据类型。


#### 实现原理
Bitmap 本身是用String 类型作为底层数据结构实现的一种统计二值状态的数据类型。 String类型是会保存位二进制的字节数组，所以，Redis就把字节数组的每个bit位利用起来，用来表示一个元素的二值状态。把Bitmap 看作是一个bit数组。

Bitmap 提供了 GETBIT/SETBIT操作，使用一个偏移值offset对bit数组的某一个bit位进行读和写。不过，bitmap的偏移量是从0开始算的，当使用setbit对一个bit位进行写操作时，这个bit位会被设置位1。Bitmap 还提供了BITCOUNT操作，用来统计这个bit数组中所有“1”的个数。

#### 具体实例
假设要统计ID3000 的用户在2020年8月份的签到情况，就可以按照下面的步骤。
![](images/2021-07-05-20-33-58.png)
就可以知道该用户在8月份的签到情况。


**那么如果**记录了一亿个用户10天的签到情况，你有办法统计出这10天连续签到的用户总数嘛。

在举例之前，要先知道，Bitmap支持用BITOP命令对多个Bitmap按位做“与”或“异或”的操作，操作的结果会保存到一个新的Bitmap中。

![](images/2021-07-05-20-39-23.png)

回到刚刚的问题，在统计一亿个用户连续十天的签到情况时，你可以把每天的日期当作当作key，每个key对应要给1亿位的bitmap，每个bit对应一个用户当天的签到情况。


接下来，对10个bitmap做按位“与”操作，得到的结果也是一个Bitmap，大约占12mb（10^8/8/1024/1024）的内存。

#### tips
如果只需要统计数据的二值状态，例如商品有没有，用户在不在等，就可以使用Bitmap，只用一个bit位就能表示0或1.在记录海量数据时，Bitmap能苟有效地节省内存空间。


### 基数统计
基数统计就是指统计一个集合中不重复的元素个数。对应到我们的场景中，就是统计网页的UV。

网页UV的统计有个独特的地方，就是需要去重，一个用户一天内的多次访问只能算作一次。在Redis的集合类型中，Set类型默认支持去重，所以看到有去重需求时，使用set类型。


有一个用户user1访问page1 时，你把这个信息加到set中：
```c
SADD page1:uv user1
```

但是，如果page1非常火爆，UV达到了千万，这个时候，一个set就要记录千万个用户ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都能这样的一个set，就会消耗很大的内存空间。


那什么技能完成统计，还能节省内存呢？

这里可以用到Redis 提供的 HyperLogLog了。

**HyperLogLog**是一种用于统计基数的数据集合类型，它的最大优势在于，**当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。**

在统计UV时，你可以用PFADD命令（用于向HyperLogLog中添加新元素）把访问页面的每个用户都添加到HyperLogLog中。

```c
PFADD page1:uv user1 user2 user3 user4 user5
```

接下来，就可以用PFCOUNT命令直接获得page1的UV值了，这个命令的作用就是返回HyperLogLog的统计结果。
```c
PFCOUNT page1:uv
```

HyperLogLog 的统计规则时**基于概率完成**的，因此可能有误差。


![](images/2021-07-05-21-25-17.png)




## 13 GEO是什么？ 还可以定义新的数据类型吗？

Redis的5大基本数据类型：**String，List，Hash，Set和Sorted Set**，它们可以满足大多数的数据需求，但是在面对海量数据统计时，他们的内存开销很大，而且对于一些特殊的场景，它们是无法支持的。所以，Redis还提供了**3种扩展数据类型** ， 分别是 Bitmap， HyperLogLog 和 GEO 。

这里，具体讲一讲GEO。


### 面向LBS应用的GEO数据类型
在日常生活中，我们越来越依赖搜索“附近的餐馆”，在打车软件上叫车，这些都离不开**基于位置信息服务**
（Location-Based Service,LBS）**的应用**。 LBS应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO就非常适合应用在LBS服务的场景中，来看一下它的底层结构。

#### GEO的底层结构

一般来说，在设计要给数据类型的底层结构时，我们需要知道，要处理的数据有什么访问特点。 所以，我们需要现搞清楚位置信息到底时怎么被存取的。

以叫车服务为例，来分析LBS应用中经纬度的存取特点。

1. 每一辆网约车都有一个编号（例如33），网络车需要将自己的经度信息（例如116.034579）和纬度信息（例如 39.00452）发给叫车应用。
2. 用户在叫车的时候，叫车应用会根据用户的经纬度位置（例如经度116.054579，维度39.030452），查找
用户的附近车辆，并进行匹配。
3. 等把位置相近的用户和车辆匹配上以后，叫车应用就会根据车辆的编号，获取车辆的信息，并返回给用户。

这种数据记录模式一个key(例如车ID)对应一个value(一组经纬度)。当有很多车辆信息要保存时，就需要有一个集合来保存车辆ID和经纬度的对应关系，所以，我们可以把不同车辆的ID和它们对应的经纬度信息存在Hash集合里。

![](images/2021-07-05-21-46-24.png)

同时，Hash类型的HSET操作命令，会根据key来设置相应的value 值，所以，我们可以用它来快速地更新车辆变化的经纬度信息。

但是，对于一个LBS应用来说，**除了记录经纬度信息**，**还需要根据用户的经纬度信息在车辆的hash集合中进行范围查询。**一旦涉及到范围查询，就意味着集合中的元素需要有序，但Hash类型的集合时无序的，显然不能满足我们的要求。

那么zset类型是不是合适呢？

zset类型也支持一个key对应一个value的记录模式，其中，而 value 则是元素的权重分数。更重要的是，zset 可以根据元素的权重分数排序，支持范围查询。这就能满足 LBS服务中查找相邻位置的需求了。

而这里 GEO类型的底层数据结构用zset来实现的。
用zset来保存车辆的经纬度信息，zset的元素是车辆ID， 元素的权重分数是经纬度信息，如下图所示：

![](images/2021-07-05-21-59-24.png)

这时问题来了，zset的权重分数是一个浮点数，而一组经纬度包含的是经度和维度两个值，是不能保存浮点数的。
这里用到GEO类型中的GeoHash编码了。


#### GeoHash编码
对经度和维度分别编码，然后合成一个最终编码

在进行第一次二分区时，经度范围[-180,180]会被分成两个子区间：[-180,0) 和[0,180]（我称之为左、右分
区）。此时，我们可以查看一下要编码的经度值落在了左分区还是右分区。如果是落在左分区，我们就用 0 表
示；如果落在右分区，就用 1 表示。这样一来，每做完一次二分区，我们就可以得到 1 位编码值。
然后，我们再对经度值所属的分区再做一次二分区，同时再次查看经度值落在了二分区后的左分区还是右分
区，按照刚才的规则再做 1 位编码。当做完 N 次的二分区后，经度值就可以用一个 N bit 的数来表示了。

当一组经纬度值都编完码后，我们再把它们的各自编码值组合在一起，组合的规则是：最终编码值的偶数位上
依次是经度的编码值，奇数位上依次是纬度的编码值，其中，偶数位从 0 开始，奇数位从 1 开始。
我们刚刚计算的经纬度（116.37，39.86）的各自编码值是 11010 和 10111，组合之后，第 0 位是经度的第 0位 1，第 1 位是纬度的第 0 位 1，第 2 位是经度的第 1 位 1，第 3 位是纬度的第 1 位 0，以此类推，就能得到最终编码值 1110011101，如下图所示：
![](images/2021-07-05-22-05-01.png)


#### 如何操作GEO类型？
![](images/2021-07-05-22-07-13.png)

以叫车应用的车辆匹配场景，具体如何使用这两个命令。

假设车辆ID是33，经纬度位置是（116.034579，39.030452），我们可以用一个GEO集合保存所有车辆的经纬度，集合key是cars:locations。
```c
GEOADD cars:locations 116.034579 39.030452 33
```
当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令。
例如，LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。当然， 你可以修改“5”这个参数，来返回更大或更小范围内的车辆信息。

```c
GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10
```

#### 如何自定义数据类型？



## 14 如何在Redis中保存时间序列数据？
记录用户在网站或者App上的点击行为数据，来分析用户行为。 这里的数据一般包括用户ID，行为类型（例如浏览，登录，下单等），行为发生的时间戳：

```c
UserID, Type, TimeStamp
```
比如一个物联网项目的数据存取需求，和这个很相似。我们需要周期性地统计近万台设备的实时状态，包括设备id，压力，温度，湿度，以及对应的时间戳
```c
DeviceID, Pressure, Temperature, Humidity, TimeStamp
```

这种与发生时间相关的一组数据，就是**时间序列数据**。这些数据的特点是没有严格的关系模型，记录的信息可以表示成键和值的关系，所以，并不需要专门用关系型数据库来保存。而Redis的键值数据模型，正好可以满足这里的数据存取需求。Redis基于自身数据结构以及扩展模块，提供了两种解决方案。



### 时间序列数据的读写特点
时间序列数据通常是**持续高并发写入**的，例如，需要连续记录数万个设备的实时状态值。

时间序列数据的写入就是插入数据，原来的数据不会被修改。 因此选择的数据类型复杂度尽可能要低，尽量不要阻塞。


时间序列的读 需要有 单条记录的查询（查询某个设备在某一个时刻的运行状态信息，对应的就是这个设备的一条记录），也有对某个时间范围内的数据的查询（例如每天早上八点到10点的所有设备的状态信息）


时间序列的读 ，（比如对事件序列进行聚合计算）查询模式多


针对时间序列数据的“写要快”，Redis 的高性能写特性直接就可以满足了；而针对“查询模式多”，也就是支持单点查询，范围查询和聚合计算，Redis提供了保存时间序列数据的两种方法，分别可以基**于Hash和zset**实现，以及基于**RedisTimeSeries**模块实现。



### 基于Hash 和 zset保存时间序列数据


hash和zset都是redis内在的数据类型，代码成熟和性能稳定。

**为什么保存时间序列数据，要同时使用这两种类型。**  

使用hash集合记录设备的温度值的示意图：
![](images/2021-07-05-22-39-56.png)
查询语句
```c
HGET device:temperature 202008030905
"25.1"
HMGET device:temperature 202008030905 202008030907 202008030908
1) "25.1"
2) "25.9"
3) "24.9"

```
然而hash不支持范围查询，因此使用zset来支持范围查询。


![](images/2021-07-05-22-41-51.png)

zset使用时间戳来作为权重排序。

范围查询
```c
ZRANGEBYSCORE device:temperature 202008030907 202008030910
1) "25.9"
2) "24.9"
3) "25.3"
4) "25.2"
```


然而，如果用了这两个数据结构可以保证 了读写要求，那么还需要满足一个，**即保证写入hash和zset是一个原子性的操作？**

使用redis 的原子性操作？
* multi命令：表示一系列原子性操作的开始。收到这个命令后，redis知道接下来收到的命令需要放到一个队列中，后续一起执行，保证原子性。
* exec命令：表示一系列原子性操作的结束。一旦redis 收到了这个命令，就表示所有要保证原子性的命令操作都已经发送完成了。




还有一个问题，如何对时间序列进行聚合计算？
**聚合计算一般被用来周期性地统计时间窗口内的数据汇总状态，在实时监控与预警等场景下会频繁执行。**


因为 Sorted Set 只支持范围查询，无法直接进行聚合计算，所以，我们只能先把时间范围内的数据取回到客户端，然后在客户端自行完成聚合计算。这个方法虽然能完成聚合计算，但是会带来一定的潜在风险，也就是大量数据在 Redis 实例和客户端间频繁传输，这会和其他操作命令竞争网络资源，导致其他操作变慢。

因此当需要进行大量的聚合计算，同时网络带宽条件不是太耗时，hash和zset的组合就不太适合了。此时，使用RedisTimeSeries就更加合适一些。


#### 基于RedisTimesSeries 模块保存事件序列数据

RedisTimeSeries 是 Redis 的一个扩展模块。它专门面向时间序列数据提供了数据类型和访问接口，并且支持在Redis 实例上直接对数据进行按时间范围的聚合计算。
因为 RedisTimeSeries 不属于 Redis 的内建功能模块，在使用时，我们需要先把它的源码单独编译成动态链接库redistimeseries.so，再使用 loadmodule 命令进行加载，如下所示：
```c
loadmodule redistimeseries.so
```


具体细节看pdf


### 总结

组合使用 Hash 和 Sorted Set，或者使用 RedisTimeSeries，在支持时间序列数据存取上各有优劣势。

* 如果你的部署环境中网络带宽高、Redis 实例内存大，可以优先考虑第一种方案；
* 如果你的部署环境中网络、内存资源有限，而且数据量大，聚合计算频繁，需要按数据集合属性查询，
可以优先考虑第二种方案。


## 15 消息队列的考验： Redis 有哪些解决方案？

现在互联网应用基本上都是采用分布式系统架构进行设计的。而很多分布式系统必备的一个基础软件就是消息队列。

消息队列要求能支持组件通信消息的快速读写，而Redis本身支持数据的告诉访问，正好可以满足消息队列的读写性能需求。不过，除了性能，消息队列还有其他的要求。 “Redis适合做消息队列嘛”

Redis 要做消息队列，首先要考虑以下两方面
* 消息队列的消息存取需求是什么？
* Redis如何实现实习队列的需求？


### 消息队列的消息存取需求
在分布式系统中，当两个组件要基于消息队列进行通信时，一个组件
会把要处理的数据以消息的形式传递给消息队列，然后，这个组件就可以继续执行其他操作了；远端的另一个组件从消息队列中把消息读取出来，再在本地进行处理。
![](images/2021-07-06-10-37-23.png)
![](images/2021-07-06-10-37-46.png)

在使用消息队列时，消费者可以异步读取生产者消息，然后再进行处理，这样一来，即使生产者发送的消息的速度远远超过了消费者处理消息的速度，生产者已经发送的消息也可以缓存在消息队列中，避免阻塞生产者，这是消息队列作为分布式组件通信的一大优势。

消息队列再存取消息时，必须要满足三个需求，分别是**消息保序，处理重复的消息和保证消息可靠性。**

#### 消息保序
虽然消费者是异步处理消息，但是，消费者仍然需要按照生产者发送消息的顺序来处理消息，避免后发送的消息被先处理了。对于要求消息保序的场景来说，一旦出现这种消息被乱序处理的情况，就可能会导致业务逻辑被错误执行，从而给业务方造成损失。

RocketMQ 可以按照 任务id来分配 同一个队列

#### 重复消息
消费者从消息队列读取消息时，有时会因为网络堵塞而出现消息重传的情况。此时，消费者可能会收到多条重复的消息。对于重复的消息，消费者如果多次处理的话，就可能造成一个业务逻辑被多次执行，如果业务逻辑正好是要修改数据，那就会出现数据被多次修改的问题了。

#### 消息可靠性
另外，消费者在处理消息的时候，还可能出现因为故障或宕机导致消息没有处理完成的情况。此时，消息队列需要能提供消息可靠性的保证，也就是说，当消费者重启后，可以重新读取消息再次进行处理，否则，就会出现消息漏处理的问题了。


Redis 的 List 和 Streams 两种数据类型，就可以满足消息队列的这三个需求。我们先来了解下基于 List 的消息队列实现方法。

### 基于List的消息队列解决方案

#### 顺序消息
List 本身就是按照先进先出的顺序对数据进行存取的，所以，如果使用List作为消息队列保存消息的话，就已经能满足消息保序的需求了。
![](images/2021-07-06-10-52-37.png)

注： 在生产者往List 写入数据时，List并不会主动地通知消费者有消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用RPOP命令，（while循环不断读取），
这样就会导致消费者程序的CPU一直消耗在执行RPOP命令上，带来不必要的性能损失。

Redis 提供了**RBPOP命令， BRPOP 命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。**

#### 重复消息
要解决重复消息的问题，消息队列需要能够对**重复消息进行判断**。


一方面，消息队列要能给每一个消息提供全局唯一的 ID 号；另一方面，消费者程序要把已经处理过的消息的ID 号记录下来
。
当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了。这种处理特性也称为幂等性，幂等性就是指，对于同一条消息，消费者收到一次的处理结果和收到多次的处理结果是一致的
![](images/2021-07-06-11-03-18.png)

#### 可靠性
![](images/2021-07-06-11-02-21.png)
**为了留存消息，List 类型 提供了BRPOPLPUSH命令，这个命令的作用是让消费者程序从一个List读取消息，同时，Redis 会把这个消息再插入到另一个List 留存。**

### 基于Streams 的消息队列解决方案
Streams 是 Redis 专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令。

* **XADD**: 插入消息，保证有序，可以自动生成全局唯一ID；
* **XREAD**:用于读取消息，可以按ID读取数据；
* **XREADGROUP**:按消费组形式读取消息；
* **XPENDING 和  XACK**: XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而XACK命令用于向消息队列确认消息处理已完成。



## 16 异步机制：如何避免单线程模型的阻塞？

影响Redis性能的5大方面的潜在因素，分别是：
* Redis内部的阻塞式操作
* CPU核和NUMA架构的影响
* Redis关键系统配置
* Redis内存碎片
* Redis缓冲区。

这章介绍**Redis内部的阻塞式操作以及应对的方法**。


### Redis 实例有哪些阻塞点？
Redis 实例在运行时，要和很多对象进行交互，这些不同的交互就会涉及不同的操作，
* 客户端： 网络IO，键值对增删改查操作，数据库操作；
* 磁盘：生成RDB快照，记录AOF日志，AOF日志重写
* 主从节点：主库完成，传输RDB文件，从库接收RDB文件，清空数据库，加载RDB文件；
* 切片集群实例：向其他实例传输哈希槽信息，数据迁移

![](images/2021-07-07-20-01-14.png)


#### 1.和客户端交互时的阻塞点
网络 IO 有时候会比较慢，但是 Redis 使用了 IO 多路复用机制，避免了主线程一直处在等待网络连接或请求到来的状态，所以，网络 IO 不是导致 Redis 阻塞的因素。

键值对的增删改查操作是 Redis 和客户端交互的主要部分，也是 Redis 主线程执行的主要任务。所以，**复杂度高的增删改查**操作肯定会阻塞 Redis。

如何判断操作复杂度，**看操作的复杂度是否为O(N).**

Redis 中涉及集合的操作复杂度通常为O（N）,例如集合元素全量查询操作 HGETALL,SMEMBERS，以及集合的聚合统计操作， 这些操作可以作为Redis的第一个阻塞点：**集合全量查询和聚合操作。**

除此之后，**集合自身的删除操作同样也有潜在的阻塞风险。**（删除操作的本质是要释放键值对占用的内存，在释放内存时，操作系统需要把释放掉的内存块插入到一个空闲内存块的链表，以便后续进行管理以及再分配。释放内存过大时，空闲内存块链表操作时间就会操作增加）。

那什么时候释放大量内存。删除大量键值对数据的时候。删除包含了大量元素的集合，也成为bigkey删除

![](images/2021-07-07-20-36-40.png)

**bigkey 删除操作就是Redis的第二个阻塞点**

既然清除键值对都是潜在的阻塞点了，那么在Redis的数据库级别操作中，清空数据库必然也是一个潜在的阻塞风险。

#### 2.和磁盘交互时的阻塞点

磁盘IO一般比较费时费力，因此Redis 开发者认为磁盘IO会带来阻塞，所以就把Redis涉及为采用子进程的方式生成RDB快照文件，以及执行AOF日志重写操作。

但是，Redis直接记录AOF日志时，会根据不同的写回策略对数据做落盘保存。一个同步写磁盘的操作的耗时大约时1~2ms，如果有大量的写操作需要记录在AOF记录中，并同步写回的话，就会阻塞主线程了。

这就是Redis的**第四个阻塞点：AOF日志同步写。**


#### 3.主从节点的阻塞点
在主从集群中，主库需要生成RDB文件，并传输给从库。主库在复制的过程中，创建和传输 RDB 文件都是由子进程来完成的，不会阻塞主线程。但是，对于从库来说，它在接收了 RDB 文件后，需要使用 **FLUSHDB **命令清空当前数据库，这就正好撞上了刚才我们分析的**第三个阻塞点。**

此外，从库在清空当前数据库后，还需要把 RDB 文件加载到内存，这个过程的快慢和 RDB 文件的大小密切相关，RDB 文件越大，加载过程越慢，所以，加载 RDB 文件就成为了 Redis 的第五个阻塞点。


#### 4.切片集群实例交互时的阻塞点



上面存在着5大阻塞，那么这五大阻塞如果可以异步执行，则可以减少主线程的阻塞。


### 哪些阻塞点可以异步执行？
如果有一个操作能被异步执行，就意味着，它并不是Redis主线程的关键路径上的操作。
即Redis不用返回数据结果的操作。

![](images/2021-07-07-20-51-45.png)

对于Redis来说，**读操作时典型的关键路径操作**，因为客户端发送了读操作之后，就需要读取的数据返回。而第一个Redis阻塞点“集合全量查询以及聚合操作”都涉及到了读操作，因此不能进行异步操作。


而删除操作不需要给客户端返回结果，因此 第二个阻塞点 ，第三个都可以使用后台子进程来异步操作。



第四个阻塞点“AOF日志同步写”来说，为了保证数据可靠性，Redis 实例需要保证AOF日志中的操作记录已经落盘，这个操作不需要返回结果给客户端，因此可以启动一个子进程来执行AOF日志的同步写，而不用让主线程等待AOF日志的写完成。


加载RDB需要主线程加载。


### 异步的子线程机制
Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。
![](images/2021-07-07-21-04-43.png)

### 小结
在上文的五大阻塞点中，bigkey删除，清空数据库，AOF日志同步写不属于关键路径操作，可以使用**异步子线程**机制来完成。


## 17 为什么CPU结构也会影响Redis 的性能？


## 18 波动的响应延迟：如何应对变慢的Redis？（上）


## 18 波动的响应延迟：如何应对变慢的Redis？（下）